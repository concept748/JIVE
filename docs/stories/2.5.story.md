# Story 2.5: Initialize Orchestrator Worker

## Status

Draft

## Story

**As a** System,
**I want** a background worker that processes webhook events via BullMQ job queues,
**so that** artifact scanning, conflict detection, and gate evaluation run asynchronously without blocking the web server.

## Acceptance Criteria

1. Orchestrator worker created in `lib/orchestrator/worker.ts`
2. BullMQ queues created: `artifact-scan`, `conflict-detection`, `gate-evaluation`
3. Webhook handler enqueues `artifact-scan` job when push event received
4. Worker processes `artifact-scan` job (placeholder implementation logs job)
5. Redis pub/sub integrated: worker publishes events to `project:{id}` channel
6. Railway deployment configured for orchestrator service
7. Worker connects to Postgres and Redis on startup
8. Health monitoring: worker logs heartbeat every 30 seconds
9. Job retries configured (3 attempts with exponential backoff)
10. Manual job enqueue test: `POST /api/jobs/enqueue` (dev endpoint)
11. All tests pass (`pnpm test`)

## Tasks / Subtasks

- [ ] **Task 1: Install BullMQ Dependencies** (AC: 2, 9)
  - [ ] Install BullMQ: `pnpm add bullmq`
  - [ ] Verify `ioredis` already installed (from Story 2.1)
  - [ ] Verify package.json includes `bullmq`
  - [ ] Run `pnpm type-check` to ensure no errors

- [ ] **Task 2: Define Job Types & Schemas** (AC: 2, 4)
  - [ ] Create `lib/orchestrator/types/job.ts` file
  - [ ] Define job data interfaces:

    ```typescript
    export interface ArtifactScanJobData {
      projectId: string;
      repoUrl: string;
      branch: string;
      commitSha: string;
      webhookEventId: string;
    }

    export interface ConflictDetectionJobData {
      projectId: string;
      artifactIds: string[]; // Artifacts to check for conflicts
    }

    export interface GateEvaluationJobData {
      projectId: string;
      storyId: string;
      gateType: 'unit-tests' | 'integration-tests' | 'type-check' | 'lint';
    }

    export type JobData =
      | ArtifactScanJobData
      | ConflictDetectionJobData
      | GateEvaluationJobData;
    ```

  - [ ] Define job result types:
    ```typescript
    export interface JobResult {
      success: boolean;
      message: string;
      data?: any;
      error?: string;
    }
    ```
  - [ ] Export all types

- [ ] **Task 3: Create Queue Definitions** (AC: 2)
  - [ ] Create `lib/orchestrator/queues.ts` file
  - [ ] Import BullMQ and Redis client
  - [ ] Create queue instances:

    ```typescript
    import { Queue } from 'bullmq';
    import { redis } from '@/lib/db/redis';

    const connection = {
      host: redis.options.host,
      port: redis.options.port,
      password: redis.options.password,
    };

    export const artifactScanQueue = new Queue('artifact-scan', {
      connection,
      defaultJobOptions: {
        attempts: 3,
        backoff: {
          type: 'exponential',
          delay: 2000, // Start with 2 seconds
        },
        removeOnComplete: 100, // Keep last 100 completed jobs
        removeOnFail: 500, // Keep last 500 failed jobs
      },
    });

    export const conflictDetectionQueue = new Queue('conflict-detection', {
      connection,
      defaultJobOptions: {
        attempts: 3,
        backoff: { type: 'exponential', delay: 2000 },
        removeOnComplete: 100,
        removeOnFail: 500,
      },
    });

    export const gateEvaluationQueue = new Queue('gate-evaluation', {
      connection,
      defaultJobOptions: {
        attempts: 3,
        backoff: { type: 'exponential', delay: 2000 },
        removeOnComplete: 100,
        removeOnFail: 500,
      },
    });
    ```

  - [ ] Export queue instances

- [ ] **Task 4: Create Job Handlers** (AC: 4)
  - [ ] Create `lib/orchestrator/jobs/artifact-scan.ts` file
  - [ ] Implement placeholder handler:

    ```typescript
    import { Job } from 'bullmq';
    import { ArtifactScanJobData, JobResult } from '../types/job';
    import { prisma } from '@/lib/db/prisma';

    export async function artifactScanHandler(
      job: Job<ArtifactScanJobData>,
    ): Promise<JobResult> {
      const { projectId, repoUrl, branch, commitSha, webhookEventId } =
        job.data;

      console.log(`[artifact-scan] Processing job ${job.id}`, {
        projectId,
        repoUrl,
        branch,
        commitSha,
      });

      try {
        // Placeholder implementation (Epic 4 will implement full scanning)
        // For now, just log and mark webhook as processed
        await prisma.webhookEvent.update({
          where: { id: webhookEventId },
          data: {
            processed: true,
            processedAt: new Date(),
          },
        });

        console.log(`[artifact-scan] Completed job ${job.id}`);

        return {
          success: true,
          message: 'Artifact scan completed (placeholder)',
          data: {
            artifactsScanned: 0, // Placeholder
          },
        };
      } catch (error) {
        console.error(`[artifact-scan] Failed job ${job.id}:`, error);

        // Update webhook event with error
        await prisma.webhookEvent.update({
          where: { id: webhookEventId },
          data: {
            retryCount: { increment: 1 },
            errorMessage:
              error instanceof Error ? error.message : 'Unknown error',
          },
        });

        return {
          success: false,
          message: 'Artifact scan failed',
          error: error instanceof Error ? error.message : 'Unknown error',
        };
      }
    }
    ```

  - [ ] Create `lib/orchestrator/jobs/conflict-detection.ts` (placeholder)
  - [ ] Create `lib/orchestrator/jobs/gate-evaluation.ts` (placeholder)

- [ ] **Task 5: Create Orchestrator Worker** (AC: 1, 7, 8)
  - [ ] Create `lib/orchestrator/worker.ts` file
  - [ ] Import BullMQ Worker and job handlers
  - [ ] Create worker instances:

    ```typescript
    import { Worker } from 'bullmq';
    import { prisma } from '@/lib/db/prisma';
    import { redis } from '@/lib/db/redis';
    import { artifactScanHandler } from './jobs/artifact-scan';
    import { ArtifactScanJobData } from './types/job';

    const connection = {
      host: redis.options.host,
      port: redis.options.port,
      password: redis.options.password,
    };

    export async function startOrchestrator() {
      console.log('[orchestrator] Starting workers...');

      // Test database connection
      try {
        await prisma.$queryRaw`SELECT 1`;
        console.log('[orchestrator] Database connected');
      } catch (error) {
        console.error('[orchestrator] Database connection failed:', error);
        process.exit(1);
      }

      // Test Redis connection
      try {
        await redis.ping();
        console.log('[orchestrator] Redis connected');
      } catch (error) {
        console.error('[orchestrator] Redis connection failed:', error);
        process.exit(1);
      }

      // Create workers
      const artifactScanWorker = new Worker<ArtifactScanJobData>(
        'artifact-scan',
        artifactScanHandler,
        { connection },
      );

      artifactScanWorker.on('completed', (job) => {
        console.log(`[orchestrator] Job ${job.id} completed`);
      });

      artifactScanWorker.on('failed', (job, err) => {
        console.error(`[orchestrator] Job ${job?.id} failed:`, err);
      });

      // Heartbeat monitoring
      setInterval(() => {
        console.log('[orchestrator] Heartbeat - workers running');
      }, 30000); // 30 seconds

      console.log('[orchestrator] Workers started successfully');

      // Graceful shutdown
      process.on('SIGTERM', async () => {
        console.log('[orchestrator] Shutting down...');
        await artifactScanWorker.close();
        await prisma.$disconnect();
        await redis.quit();
        process.exit(0);
      });
    }

    // Start orchestrator if run directly
    if (require.main === module) {
      startOrchestrator().catch((error) => {
        console.error('[orchestrator] Fatal error:', error);
        process.exit(1);
      });
    }
    ```

  - [ ] Export `startOrchestrator` function

- [ ] **Task 6: Update Webhook Handler to Enqueue Jobs** (AC: 3)
  - [ ] Open `app/api/webhooks/github/route.ts`
  - [ ] Import `artifactScanQueue` from queues
  - [ ] After webhook verification, enqueue job:

    ```typescript
    import { artifactScanQueue } from '@/lib/orchestrator/queues';

    export async function POST(req: Request) {
      // ... existing webhook verification code ...

      // Enqueue artifact scan job
      await artifactScanQueue.add('scan', {
        projectId: project.id,
        repoUrl: payload.repository.clone_url,
        branch: payload.ref.replace('refs/heads/', ''),
        commitSha: payload.after,
        webhookEventId: deliveryId,
      });

      console.log(
        `[webhook] Enqueued artifact-scan job for delivery ${deliveryId}`,
      );

      return new Response(JSON.stringify({ accepted: true }), {
        status: 202,
        headers: { 'Content-Type': 'application/json' },
      });
    }
    ```

- [ ] **Task 7: Integrate Redis Pub/Sub** (AC: 5)
  - [ ] Open `lib/orchestrator/jobs/artifact-scan.ts`
  - [ ] Import Redis client
  - [ ] Publish event after job completion:

    ```typescript
    import { redis } from '@/lib/db/redis';

    // After successful scan
    await redis.publish(
      `project:${projectId}`,
      JSON.stringify({
        event: 'artifact_scan_completed',
        projectId,
        timestamp: new Date().toISOString(),
        payload: {
          jobId: job.id,
          artifactsScanned: 0,
        },
      }),
    );
    ```

  - [ ] Publish event on failure as well:
    ```typescript
    await redis.publish(
      `project:${projectId}`,
      JSON.stringify({
        event: 'artifact_scan_failed',
        projectId,
        timestamp: new Date().toISOString(),
        payload: {
          jobId: job.id,
          error: error.message,
        },
      }),
    );
    ```

- [ ] **Task 8: Create Manual Job Enqueue Endpoint (Dev Only)** (AC: 10)
  - [ ] Create `app/api/jobs/enqueue/route.ts` file
  - [ ] Implement POST handler:

    ```typescript
    import { NextRequest, NextResponse } from 'next/server';
    import { artifactScanQueue } from '@/lib/orchestrator/queues';

    export async function POST(req: NextRequest) {
      // Only allow in development/staging
      if (process.env.NODE_ENV === 'production') {
        return NextResponse.json(
          { error: 'Endpoint disabled in production' },
          { status: 403 },
        );
      }

      const body = await req.json();
      const { queue, data } = body;

      if (queue !== 'artifact-scan') {
        return NextResponse.json(
          { error: 'Only artifact-scan queue supported' },
          { status: 400 },
        );
      }

      const job = await artifactScanQueue.add('manual-test', data);

      return NextResponse.json({
        jobId: job.id,
        queue: 'artifact-scan',
        data: job.data,
      });
    }
    ```

  - [ ] Test: `curl -X POST http://localhost:3000/api/jobs/enqueue -d '{"queue":"artifact-scan","data":{...}}'`

- [ ] **Task 9: Create Orchestrator Build Scripts** (AC: 6)
  - [ ] Open `package.json`
  - [ ] Add scripts:
    ```json
    {
      "scripts": {
        "build:orchestrator": "tsc --project tsconfig.orchestrator.json",
        "start:orchestrator": "node dist/lib/orchestrator/worker.js",
        "dev:orchestrator": "tsx lib/orchestrator/worker.ts"
      }
    }
    ```
  - [ ] Create `tsconfig.orchestrator.json`:
    ```json
    {
      "extends": "./tsconfig.json",
      "compilerOptions": {
        "outDir": "./dist",
        "module": "commonjs",
        "moduleResolution": "node"
      },
      "include": ["lib/orchestrator/**/*", "lib/db/**/*"],
      "exclude": ["node_modules", "tests"]
    }
    ```

- [ ] **Task 10: Configure Railway Deployment** (AC: 6)
  - [ ] Create `railway.orchestrator.json`:
    ```json
    {
      "$schema": "https://railway.app/railway.schema.json",
      "build": {
        "builder": "NIXPACKS",
        "buildCommand": "pnpm install && npx prisma generate && pnpm build:orchestrator"
      },
      "deploy": {
        "startCommand": "pnpm start:orchestrator",
        "numReplicas": 1,
        "restartPolicyType": "ON_FAILURE",
        "restartPolicyMaxRetries": 10
      }
    }
    ```
  - [ ] Update Railway dashboard:
    - Create new service: "jive-orchestrator"
    - Link to staging branch
    - Set `RAILWAY_CONFIG_FILE=railway.orchestrator.json`
    - Connect to same Postgres/Redis instances as web service
  - [ ] No public port required (background worker)

- [ ] **Task 11: Write Integration Tests** (AC: 4, 5, 9, 11)
  - [ ] Create `tests/integration/orchestrator/jobs.test.ts`
  - [ ] Setup test database and Redis
  - [ ] Write test: `enqueues artifact-scan job`
    - [ ] Create test project in database
    - [ ] Enqueue job via `artifactScanQueue.add()`
    - [ ] Assert job added to queue
  - [ ] Write test: `worker processes artifact-scan job`
    - [ ] Start worker
    - [ ] Enqueue job
    - [ ] Wait for job completion
    - [ ] Assert webhook event marked as processed
    - [ ] Stop worker
  - [ ] Write test: `worker retries failed job 3 times`
    - [ ] Mock `prisma.webhookEvent.update()` to throw error
    - [ ] Enqueue job
    - [ ] Wait for 3 retry attempts
    - [ ] Assert job failed after 3 attempts
  - [ ] Write test: `worker publishes event to Redis pub/sub`
    - [ ] Subscribe to `project:{id}` channel
    - [ ] Enqueue and process job
    - [ ] Assert event published with correct payload
  - [ ] Write test: `manual enqueue endpoint creates job`
    - [ ] POST to `/api/jobs/enqueue`
    - [ ] Assert job created in queue
    - [ ] Assert response contains job ID

- [ ] **Task 12: Write Unit Tests for Job Handlers** (AC: 4, 11)
  - [ ] Create `tests/unit/orchestrator/artifact-scan.test.ts`
  - [ ] Mock Prisma and Redis clients
  - [ ] Write test: `artifact-scan handler marks webhook as processed`
    - [ ] Mock webhook event in database
    - [ ] Call `artifactScanHandler()` with mock job
    - [ ] Assert `prisma.webhookEvent.update()` called with `processed: true`
  - [ ] Write test: `artifact-scan handler updates retry count on failure`
    - [ ] Mock Prisma error
    - [ ] Call handler
    - [ ] Assert retry count incremented
  - [ ] Write test: `artifact-scan handler publishes Redis event`
    - [ ] Mock Redis publish
    - [ ] Call handler
    - [ ] Assert `redis.publish()` called with correct channel and payload

- [ ] **Task 13: Update Environment Variables** (AC: 7)
  - [ ] Verify `.env.example` already has:
    - `DATABASE_URL` (from Story 2.1)
    - `REDIS_URL` (from Story 2.1)
  - [ ] No new environment variables needed for Story 2.5

- [ ] **Task 14: Test Locally** (AC: 1-10)
  - [ ] Start web server: `pnpm dev`
  - [ ] Start orchestrator: `pnpm dev:orchestrator`
  - [ ] Trigger webhook: Use GitHub webhook or manual enqueue endpoint
  - [ ] Verify orchestrator logs show job processing
  - [ ] Verify webhook event marked as `processed: true` in database
  - [ ] Verify heartbeat logs every 30 seconds
  - [ ] Stop orchestrator with `Ctrl+C`, verify graceful shutdown

- [ ] **Task 15: Deploy to Railway** (AC: 6)
  - [ ] Push Story 2.5 implementation to staging branch
  - [ ] Verify Railway builds and deploys orchestrator service
  - [ ] Check Railway logs for:
    - Database connection success
    - Redis connection success
    - Workers started successfully
    - Heartbeat logs every 30 seconds
  - [ ] Trigger test webhook to staging web service
  - [ ] Verify orchestrator processes job (check Railway logs)
  - [ ] Verify webhook event marked as processed in Railway Postgres

- [ ] **Task 16: Verify All Tests Pass** (AC: 11)
  - [ ] Run unit tests: `pnpm test tests/unit/orchestrator/`
  - [ ] Run integration tests: `pnpm test tests/integration/orchestrator/`
  - [ ] Verify test coverage >80% for job handlers
  - [ ] Run `pnpm type-check` to ensure no TypeScript errors
  - [ ] Run `pnpm lint` to ensure no linting errors

## Dev Notes

### Previous Story Insights

**[From Story 2.1, 2.2, 2.3, 2.4]**

Key context from previous stories:

1. **Prisma Setup:** Story 2.1 created `webhook_events` table. Story 2.5 updates `processed` and `processedAt` fields after job completion.

2. **Redis Setup:** Story 2.1 created Redis client singleton. Story 2.5 uses Redis for BullMQ queues and pub/sub.

3. **Webhook Handler:** Story 1.3 created webhook verification. Story 2.5 extends webhook handler to enqueue jobs.

4. **MCP Server:** Story 2.4 created MCP tools. Future stories will enable MCP tools to subscribe to Redis pub/sub events for real-time updates.

### Architecture Context

**[Source: docs/architecture.md#orchestrator-worker]**

#### Orchestrator Architecture (lines 1570-1650)

**Purpose:**

The orchestrator worker is a background service that processes asynchronous tasks triggered by webhooks:

- Artifact scanning (clone repo, parse files, extract metadata)
- Conflict detection (compare artifacts for inconsistencies)
- Quality gate evaluation (run tests, type-checks, linting)

**Why Background Worker?**

- Webhook handlers must respond within 10 seconds (GitHub timeout)
- Artifact scanning can take 30+ seconds (clone repo, parse files)
- Conflict detection requires comparing multiple artifacts (CPU-intensive)
- Decouples webhook ingestion from processing (failure isolation)

**[Source: docs/architecture.md#job-queue-pattern]**

#### BullMQ Job Queue Pattern (lines 1651-1700)

**Queue Structure:**

```typescript
// Queue: artifact-scan
{
  id: 'job-uuid',
  name: 'scan',
  data: {
    projectId: 'project-uuid',
    repoUrl: 'https://github.com/org/repo',
    branch: 'main',
    commitSha: 'abc123',
    webhookEventId: 'delivery-uuid'
  },
  opts: {
    attempts: 3,
    backoff: { type: 'exponential', delay: 2000 },
    timestamp: 1729996400000
  },
  returnvalue: {
    success: true,
    message: 'Artifact scan completed',
    data: { artifactsScanned: 5 }
  }
}
```

**Retry Strategy:**

- **Attempt 1:** Immediate execution
- **Attempt 2:** After 2 seconds (exponential backoff)
- **Attempt 3:** After 4 seconds (exponential backoff)
- **After 3 failures:** Job moved to failed queue

**Job Retention:**

- Keep last 100 completed jobs (for debugging)
- Keep last 500 failed jobs (for incident analysis)
- Auto-cleanup older jobs to prevent Redis memory bloat

**[Source: docs/architecture.md#redis-pubsub]**

#### Redis Pub/Sub for Real-Time Events (lines 1705-1730)

**Channel Naming:**

- `project:{projectId}` - Project-specific events
- Example: `project:abc-123` receives all events for project `abc-123`

**Event Format:**

```json
{
  "event": "artifact_scan_completed",
  "projectId": "abc-123",
  "timestamp": "2025-10-15T15:30:00Z",
  "payload": {
    "jobId": "job-uuid",
    "artifactsScanned": 5
  }
}
```

**Event Types (Phase 1):**

- `artifact_scan_completed` - Artifact scan finished successfully
- `artifact_scan_failed` - Artifact scan failed
- `conflict_detected` - Conflict found between artifacts (Epic 5)
- `gate_evaluated` - Quality gate evaluated (Epic 6)

**Subscribers:**

- Web service (WebSocket handler sends to connected clients)
- MCP server (future: real-time tool result updates)

**[Source: docs/architecture.md#orchestrator-deployment]**

#### Railway Deployment Strategy (lines 1860-1880)

**Three-Service Architecture:**

1. **Web Service:** Next.js app, port 3000, public endpoint
2. **MCP Service:** Fastify server, port 4000, public endpoint
3. **Orchestrator Service:** Node.js worker, no public port, background only

**Shared Resources:**

- **Postgres:** Single Railway Postgres instance, shared by all 3 services
- **Redis:** Single Railway Redis instance, shared by all 3 services

**Environment Variables (Auto-Injected by Railway):**

- `DATABASE_URL` - Postgres connection string
- `REDIS_URL` - Redis connection string

**Deployment Commands:**

```json
// Web service
{
  "buildCommand": "pnpm install && npx prisma generate && pnpm build",
  "startCommand": "pnpm start"
}

// MCP service
{
  "buildCommand": "pnpm install && npx prisma generate && pnpm build:mcp",
  "startCommand": "pnpm start:mcp"
}

// Orchestrator service
{
  "buildCommand": "pnpm install && npx prisma generate && pnpm build:orchestrator",
  "startCommand": "pnpm start:orchestrator"
}
```

### Testing Strategy

**[Source: docs/architecture.md#testing-strategy]**

**Integration Test Requirements for Story 2.5:**

- **Coverage Target:** All 3 queues tested (artifact-scan, conflict-detection, gate-evaluation)
- **Test Database:** Use test Postgres with sample webhook events
- **Test Redis:** Use separate Redis instance or redis-mock
- **Test Isolation:** Start/stop worker for each test, clear queues after tests
- **Test Categories:**
  1. Job Enqueue: Verify jobs added to queue
  2. Job Processing: Verify worker processes jobs and updates database
  3. Job Retry: Verify retry logic (3 attempts, exponential backoff)
  4. Pub/Sub: Verify events published to Redis channels
  5. Health Monitoring: Verify heartbeat logs

**Mock Patterns for Orchestrator:**

```typescript
// Mock BullMQ Queue
vi.mock('bullmq', () => ({
  Queue: vi.fn(() => ({
    add: vi.fn().mockResolvedValue({ id: 'job-uuid' }),
  })),
  Worker: vi.fn(() => ({
    on: vi.fn(),
    close: vi.fn(),
  })),
}));

// Mock Prisma
vi.mock('@/lib/db/prisma', () => ({
  prisma: {
    webhookEvent: {
      update: vi
        .fn()
        .mockResolvedValue({ id: 'webhook-uuid', processed: true }),
    },
  },
}));

// Mock Redis
vi.mock('@/lib/db/redis', () => ({
  redis: {
    publish: vi.fn().mockResolvedValue(1),
    ping: vi.fn().mockResolvedValue('PONG'),
  },
}));
```

### Tech Stack Additions

**New Dependencies for Story 2.5:**

| Dependency | Version | Purpose                | Rationale                                                  |
| ---------- | ------- | ---------------------- | ---------------------------------------------------------- |
| bullmq     | 5+      | Redis-backed job queue | Reliable job processing with retries, priority, scheduling |

**Installation Commands:**

```bash
pnpm add bullmq
```

**Note:** `ioredis` already installed in Story 2.1. BullMQ uses ioredis internally for Redis communication.

### File Locations

**New Files Created in Story 2.5:**

```
jive/
├── lib/
│   └── orchestrator/
│       ├── types/
│       │   └── job.ts                # NEW - Job data types
│       ├── queues.ts                 # NEW - Queue definitions
│       ├── worker.ts                 # NEW - Orchestrator worker entry point
│       └── jobs/
│           ├── artifact-scan.ts      # NEW - Artifact scan job handler
│           ├── conflict-detection.ts # NEW - Conflict detection job handler (placeholder)
│           └── gate-evaluation.ts    # NEW - Gate evaluation job handler (placeholder)
├── app/
│   └── api/
│       └── jobs/
│           └── enqueue/
│               └── route.ts          # NEW - Manual job enqueue endpoint (dev only)
├── tests/
│   ├── unit/
│   │   └── orchestrator/
│   │       └── artifact-scan.test.ts # NEW - Artifact scan handler unit tests
│   └── integration/
│       └── orchestrator/
│           └── jobs.test.ts          # NEW - Job queue integration tests
├── tsconfig.orchestrator.json        # NEW - TypeScript config for orchestrator
└── railway.orchestrator.json         # NEW - Railway config for orchestrator service
```

**Modified Files:**

```
app/api/webhooks/github/route.ts  # UPDATE - Enqueue artifact-scan job
package.json                       # UPDATE - Add orchestrator build/start scripts
```

### Coding Standards

**[Source: docs/architecture.md#coding-standards]**

**Critical Rules for Story 2.5:**

1. **Job Handler Pattern:** All handlers return `JobResult` type:

   ```typescript
   async function handler(job: Job<JobData>): Promise<JobResult> {
     try {
       // Process job
       return { success: true, message: '...', data: {...} };
     } catch (error) {
       return { success: false, message: '...', error: error.message };
     }
   }
   ```

2. **Error Handling:** Never throw errors from job handlers (return error result instead):

   ```typescript
   // Bad
   throw new Error('Job failed');

   // Good
   return {
     success: false,
     message: 'Job failed',
     error: error.message,
   };
   ```

3. **Graceful Shutdown:** Always close workers and disconnect clients on SIGTERM:

   ```typescript
   process.on('SIGTERM', async () => {
     await worker.close();
     await prisma.$disconnect();
     await redis.quit();
     process.exit(0);
   });
   ```

4. **Logging:** Use structured logging with job ID and project ID:

   ```typescript
   console.log(`[artifact-scan] Processing job ${job.id}`, {
     projectId,
     repoUrl,
   });
   ```

5. **Type Safety:** Use BullMQ generic types for job data:
   ```typescript
   const worker = new Worker<ArtifactScanJobData>(
     'artifact-scan',
     handler,
     options,
   );
   ```

### Deployment Strategy

**[Source: docs/architecture.md#deployment-architecture]**

**Railway Orchestrator Service Setup:**

1. **Create Service:**
   - Railway dashboard → New Service → "jive-orchestrator"
   - Link to GitHub repo, staging branch
   - Set `RAILWAY_CONFIG_FILE=railway.orchestrator.json`

2. **Environment Variables:**
   - `DATABASE_URL` - Auto-injected by Railway (connect to existing Postgres)
   - `REDIS_URL` - Auto-injected by Railway (connect to existing Redis)
   - No new variables needed

3. **Deployment:**
   - No public port (background worker only)
   - Health check: Monitor Railway logs for heartbeat messages
   - Restart policy: ON_FAILURE with 10 max retries

**Monitoring:**

- **Heartbeat Logs:** Worker logs heartbeat every 30 seconds
- **Job Metrics:** BullMQ provides built-in metrics (completed, failed, active jobs)
- **Railway Logs:** View real-time worker logs in Railway dashboard

**Scaling:**

- Phase 1: Single orchestrator instance (sufficient for low volume)
- Phase 2: Horizontal scaling (multiple workers, BullMQ handles concurrency)

### Security Considerations

**[Source: docs/architecture.md#security-requirements]**

**Job Security:**

1. **Job Data Validation:** Validate all job data before processing
2. **Webhook Verification:** Only enqueue jobs from verified webhooks (HMAC-SHA256)
3. **Project Access Control:** Verify project exists before processing job

**Manual Enqueue Endpoint:**

- **Dev/Staging Only:** Disabled in production (`NODE_ENV === 'production'`)
- **No Authentication:** Future enhancement - add auth for dev endpoint
- **Rate Limiting:** Future enhancement - rate limit manual enqueue

**Pub/Sub Security:**

- **Channel Isolation:** Use project-specific channels (`project:{id}`)
- **No Authorization:** Redis pub/sub has no built-in auth (future: encrypt payloads)

### Relationship to Future Stories

**Story 2.5 Foundation for:**

- **Epic 4 (Artifact Tracking):** `artifact-scan` job implements full scanning logic
- **Epic 5 (Conflict Detection):** `conflict-detection` job implements conflict detection
- **Epic 6 (Quality Gates):** `gate-evaluation` job runs tests and checks
- **Epic 7 (WebSocket Real-Time):** Web service subscribes to Redis pub/sub for real-time updates

**Future Enhancements (Deferred):**

- Horizontal scaling (multiple worker instances)
- Job priority queues (high/low priority)
- Scheduled jobs (cron-based artifact scans)
- Dead letter queue (manual intervention for failed jobs)
- Job cancellation (cancel long-running jobs)

### Performance Considerations

**Job Processing Performance:**

- **Target Latency:** <30 seconds for artifact scan job
- **Concurrency:** BullMQ processes jobs in parallel (default: 1 job at a time per worker)
- **Future Optimization:** Increase concurrency to 5 jobs per worker

**Redis Performance:**

- **Queue Overhead:** Minimal (<1ms per job enqueue/dequeue)
- **Pub/Sub Latency:** <5ms for event publishing
- **Memory Usage:** 100 completed + 500 failed jobs ≈ 1 MB per queue

**Database Performance:**

- **Webhook Update:** Single `UPDATE` query per job (<10ms)
- **Connection Pooling:** PgBouncer handles connection pooling (Railway managed)

**Retry Performance:**

- **Exponential Backoff:** 2s, 4s delay (prevents Redis overload)
- **Max Retries:** 3 attempts (balance between reliability and resource usage)

## Change Log

| Date       | Version | Description                                  | Author |
| ---------- | ------- | -------------------------------------------- | ------ |
| 2025-10-15 | 1.0     | Story created for Epic 2 orchestrator worker | SM Bob |

## Dev Agent Record

### Agent Model Used

_To be filled by Dev Agent_

### Debug Log References

_To be filled by Dev Agent_

### Completion Notes

_To be filled by Dev Agent_

### File List

_To be filled by Dev Agent_

## QA Results

_To be filled by QA Agent after implementation_
